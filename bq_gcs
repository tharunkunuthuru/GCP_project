from google.cloud import bigquery, storage
import json
import os
import logging
import pandas as pd 

PROJECT_ID = 'fleet-geode-425017-g6'  
DATASET_ID = 'machine112'
TABLE_ID = 'machinedata'
BUCKET_NAME = 'processed_data1595'


def bigquery_to_gcs(request):
    try:
        bigquery_client = bigquery.Client(project=PROJECT_ID)
        table_ref = bigquery_client.dataset(DATASET_ID).table(TABLE_ID)
        table = bigquery_client.get_table(table_ref)

        # Fetch distinct machine IDs
        machine_ids_query = f"""
            SELECT DISTINCT machine_id
            FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`
        """
        machine_ids_job = bigquery_client.query(machine_ids_query)
        machine_ids = [row['machine_id'] for row in machine_ids_job.result()]

        storage_client = storage.Client(project=PROJECT_ID)
        bucket = storage_client.bucket(BUCKET_NAME)

        field_names = ['humidity', 'machine_id', 'pressure', 'temperature', 'timestamp']
        machine_data = {}

        for machine_id in machine_ids:
            # Fetch up to 1000 records for each machine
            query = f"""
                SELECT *
                FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`
                WHERE machine_id = '{machine_id}'
                LIMIT 1000
            """
            query_job = bigquery_client.query(query)
            rows = query_job.result()

            machine_data[machine_id] = [row for row in rows]

        for machine_id, data in machine_data.items():
            csv_data = ','.join(field_names) + '\n'  # Add field names as the first row
            csv_data += '\n'.join([','.join([str(row[field]) for field in field_names]) for row in data])
            blob = bucket.blob(f"machine_{machine_id}_data.csv")
            blob.upload_from_string(csv_data, content_type='text/csv')

        return f"Data transferred for machines: {', '.join(machine_data.keys())}", 200

    except Exception as e:
        logging.exception("An error occurred:")
        return f"Error: {str(e)}", 500 





requirements

google-cloud-bigquery
google-cloud-storage
pandas
db-dtypes
